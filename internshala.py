# -*- coding: utf-8 -*-
"""internshala.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ij6AJ3WtS1t4M2m9dskKaCHzIEMH7XJS
"""

import cv2
import numpy as np
from datetime import datetime
from google.colab.patches import cv2_imshow

def process_video(input_video_path, output_video_path):
    try:
        # Define color ranges for each ball (HSV format)
        color_ranges = {
            "white": ((0, 0, 190), (180, 25, 255)),   # HSV range for white
            "orange": ((5, 150, 150), (15, 255, 255)),  # HSV range for orange
            "blue": ((90, 120, 100), (130, 255, 255)),  # HSV range for blue
            "yellow": ((20, 100, 100), (30, 255, 255))  # HSV range for yellow
        }

        cap = cv2.VideoCapture(input_video_path)
        if not cap.isOpened():
            print(f"Error: Could not open video file at {input_video_path}")
            return

        # Initialize video writer
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            # Convert frame to HSV for color detection
            hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

            # Process each color range
            for color_name, (lower, upper) in color_ranges.items():
                # Create a mask for the current color range
                mask = cv2.inRange(hsv_frame, lower, upper)

                # Find contours in the mask
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                # Draw contours and overlay text for each ball found
                for contour in contours:
                    # Calculate centroid of contour
                    M = cv2.moments(contour)
                    if M["m00"] > 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])

                        # Overlay text with color and timestamp
                        current_time = datetime.now().strftime("%H:%M:%S")
                        cv2.putText(frame, f"{color_name.capitalize()} - {current_time}", (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # Optionally, draw the contour on the frame
                cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)

            # Write processed frame to output video
            out.write(frame)

            # Display processed frame (optional for debugging)
            cv2_imshow(frame)

        cap.release()
        out.release()
        cv2.destroyAllWindows()

    except Exception as e:
        print(f"Error processing video: {e}")

input_video_path = "/content/AI Assignment video.mp4"  # Update with your actual path
output_video_path = "/content/processed_video.mp4"  # Update with your desired output path

process_video(input_video_path, output_video_path)

def process_video(input_video_path, output_video_path, events_log_path):
    try:
        # Define color ranges for each ball (HSV format)
        color_ranges = {
            "white": ((0, 0, 190), (180, 25, 255)),   # HSV range for white
            "orange": ((5, 150, 150), (15, 255, 255)),  # HSV range for orange
            "blue": ((90, 120, 100), (130, 255, 255)),  # HSV range for blue
            "yellow": ((20, 100, 100), (30, 255, 255))  # HSV range for yellow
        }

        # Open video capture
        cap = cv2.VideoCapture(input_video_path)
        if not cap.isOpened():
            print(f"Error: Could not open video file at {input_video_path}")
            return

        # Initialize video writer
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

        # Open text file for writing events log
        with open(events_log_path, 'w') as log_file:
            log_file.write("Time, Quadrant Number, Ball Colour, Event Type\n")

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # Process each frame to detect balls and events
                for color_name, (lower, upper) in color_ranges.items():
                    # Example logic to detect balls and events
                    # Replace with your own logic for ball detection and tracking

                    # Example event log entry
                    current_time = datetime.now().strftime("%H:%M:%S")
                    quadrant_number = "Quadrant 3"
                    event_type = "Entry"

                    # Write event to log file
                    log_file.write(f"{current_time}, {quadrant_number}, {color_name}, {event_type}\n")

                    # Overlay text and draw on the frame (not shown here for brevity)

                # Write processed frame to output video
                out.write(frame)

                # Display processed frame (optional for debugging)
                cv2_imshow(frame)

        cap.release()
        out.release()
        cv2.destroyAllWindows()

    except Exception as e:
        print(f"Error processing video: {e}")

input_video_path = "/content/AI Assignment video.mp4"  # Update with your actual path
output_video_path = "/content/processed_video.mp4"  # Update with your desired output path
events_log_path = "/content/events_log.txt"  # Update with your desired events log path

process_video(input_video_path, output_video_path, events_log_path)